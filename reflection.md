Working with Copilot made the data cleaning project a lot faster and easier to understand. At first I was not sure how much it could handle, but it ended up generating most of the structure for the script, including the functions for loading the data, cleaning it, and saving the final results. It also wrote code that checked for missing values, duplicates, and type issues, which saved me a lot of time compared to doing all of that manually.

I still had to guide it. When things went wrong, like when the file path was missing or the CSV was empty, I had to figure out what the script expected and make sure the project folders and filenames matched. This showed me that even if Copilot writes the code, I still need to understand how the project is organized and how Python reads files. Copilot made the coding part easier, but it did not replace the need to think through the structure of the project.

I also learned that Copilot is good at writing boilerplate code, but it sometimes assumes everything is already set up correctly. When something failed, I had to read the error messages, fix the folder structure, and test the script again. That part helped me understand the data cleaning process better because I could see which pieces of the script were actually being used and why.

Overall, using Copilot felt like having a very fast coding assistant. It sped up the work, handled the repetitive parts, and let me focus more on understanding the data and the logic behind the cleaning steps. I can see how tools like this can save a lot of time, but they also make it important to double check the code and make sure everything works the way I expect.
